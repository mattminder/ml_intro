{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Machine Learning?\n",
    "\n",
    "Let's say we want to find out how long an object takes to fall down from a certain height. We conduct an experiment from different heights (every 10cm) and obtain the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command makes the plots interactive. If it doesn't work, comment it out.\n",
    "%matplotlib ipympl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# read the data from csv and visualize the first three rows\n",
    "falling_times = pd.read_csv(\"../data/ball_falling_time.csv\")\n",
    "falling_times.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the data as a scatter plot, we see the following picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(falling_times):\n",
    "    plt.scatter(falling_times[\"height\"], falling_times[\"duration\"])\n",
    "    plt.xlabel(\"height (m)\")\n",
    "    plt.ylabel(\"time (s)\")\n",
    "\n",
    "plt.figure()\n",
    "plot_scatter(falling_times)\n",
    "plt.title(\"Falling times of a ball from different heights\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Approach\n",
    "A classical approach would be to formulate a hypothesis, and then validate this hypothesis using an experiment. Let's take the hypothesis that the distance travelled is proportional to the square of the time. If we plot the height against the time squared, we would expect a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(falling_times[\"height\"], falling_times[\"duration\"] ** 2)\n",
    "plt.xlabel(\"height (m)\")\n",
    "plt.ylabel(\"$time^2$ ($s^2$)\")\n",
    "plt.title(r\"Hypothesis: $height \\sim time^2$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all points are now on a straight line, we have validated the hypothesis that the height is proportional to the square of the time. We further observe that the slope is roughly 1/5th (for a height of 5m, we have $time^2 = 1s^2$), so we can deduce that \n",
    "$time^2 = \\frac{1}{5} height$. If we pull the square root, we get <br> $time = \\sqrt{\\frac{1}{5} height}$. <br><br> This model now allows us to predict the falling time.\n",
    "\n",
    "## Machine Learning Approach\n",
    "Machine Learning also has the goal of predicting the falling times depending on the height. But: We do not care about where the model comes from, we just want a model that does a good job at predicting. In order to do this, we need a **dataset** of examples with falling times.\n",
    "\n",
    "### Step 1: Formulating the Model Family\n",
    "\n",
    "We have to specify the general form of the model - the so-called **model family**. For example, we can say that we expect the solution of the model to be of the form: <br>\n",
    "$time = a * height^b$.\n",
    "\n",
    "We do not know the values of $a$ and $b$ yet: We want to find the values of $a$ and $b$ that will best fit to our data. We call such values **parameters**.\n",
    "\n",
    "In the Notebook cell below, play around with different values for a and b, until you find a combination that fits the data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS\n",
    "a = 0.45\n",
    "b = .5\n",
    "\n",
    "# don't change this\n",
    "def predict(falling_times, a, b):\n",
    "    return a * falling_times[\"height\"] ** b\n",
    "\n",
    "def plot_model(falling_times, predictions):\n",
    "    plt.plot(falling_times[\"height\"], predictions, c=\"red\")\n",
    "\n",
    "predictions = predict(falling_times, a, b)\n",
    "\n",
    "plt.figure()\n",
    "plot_scatter(falling_times)\n",
    "plot_model(falling_times, predictions)\n",
    "plt.title(r\"Model: $time = {\" + str(a) + r\"} * height^{\" + str(b) + r\"}$\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Choosing the performance metric\n",
    "Next, we have to decide how we measure the quality of our model - how do we know that a model is good after all? For example, we can measure the distance from our model predictions to the true data points, and calculate the average of that. \n",
    "\n",
    "A function that takes the true and the predicted values, and that then calculates how good we are, is called a **performance metric**. In our case, we will use the \"mean absolute error\" - the average distance from the predicted to the true points.\n",
    "\n",
    "To visualize this, we need some helper functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(true_values, predicted):\n",
    "    \"\"\"Function that calculates how much we are off on average.\"\"\"\n",
    "    return (true_values - predicted).abs().mean()\n",
    "\n",
    "# no need to understand this\n",
    "def plot_error_bars(falling_times, predictions):\n",
    "    for predicted_time, true_time, height in zip(\n",
    "        predictions,\n",
    "        falling_times[\"duration\"],\n",
    "        falling_times[\"height\"],\n",
    "    ):\n",
    "        plt.plot([height, height], [predicted_time, true_time], c=\"black\")\n",
    "\n",
    "def model_quality_plot(falling_times, a, b):\n",
    "    predictions = predict(falling_times, a, b)\n",
    "    plot_scatter(falling_times)\n",
    "    plot_model(falling_times, predictions)\n",
    "    plot_error_bars(falling_times, predictions)\n",
    "    \n",
    "    error = mean_absolute_error(falling_times[\"duration\"], predictions)\n",
    "    plt.title(f\"Mean Absolute Error: {error:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this performance metric we can now formulate an **objective**: We want to find the values $a$ and $b$ for which the performance metric is minimized.\n",
    "\n",
    "Now, again play with the values of a and b to find the best possible model (with the lowest possible error). The error tells us by how much seconds we are wrong on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS\n",
    "a = .45\n",
    "b = .51\n",
    "\n",
    "plt.figure()\n",
    "model_quality_plot(falling_times, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Optimization\n",
    "\n",
    "Instead of testing out different values ourselves, we can automate this procedure. Finding the best values for our parameters is called **model training**.\n",
    "\n",
    "For example, we can test different combinations of $a$ and $b$ and calculate the error. We then keep the parameters that worked best - i.e. that gave us the smallest error. Such a procedure that finds the best values for $a$ and $b$ for us is called an **optimization algorithm**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_to_test = np.linspace(start=0, stop=1, num=51)\n",
    "b_to_test = np.linspace(start=0, stop=1, num=51)\n",
    "\n",
    "# results will be filled as a list of dictionaries\n",
    "results = []\n",
    "for a in a_to_test:\n",
    "    for b in b_to_test:\n",
    "        predictions = predict(falling_times, a, b)\n",
    "        error = mean_absolute_error(falling_times[\"duration\"], predictions)\n",
    "        results.append(\n",
    "            {\n",
    "                \"a\": a,\n",
    "                \"b\": b,\n",
    "                \"error\": error,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# turn the list of dictionaries into a pandas DataFrame with three columns: a, b, and error\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the result as a heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_heatmap(error_df, rows=\"a\", columns=\"b\"):\n",
    "    pivoted = error_df.pivot(index=rows, columns=columns)[\"error\"]\n",
    "    \n",
    "    plt.imshow(pivoted, vmin=0, cmap=\"RdPu\", origin=\"lower\")\n",
    "    plt.xticks(range(0, len(pivoted.columns), 5), np.round(pivoted.columns[::5], 1), rotation=90)\n",
    "    plt.yticks(range(0, len(pivoted.index), 5), np.round(pivoted.index[::5], 1))\n",
    "\n",
    "    plt.xlabel(columns)\n",
    "    plt.ylabel(rows)\n",
    "\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(\"error\")\n",
    "\n",
    "plt.figure()\n",
    "plot_error_heatmap(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the result as a three-dimensional surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_surface(error_df, rows=\"a\", columns=\"b\"):\n",
    "    pivoted = error_df.pivot(index=rows, columns=columns)[\"error\"]\n",
    "    x, y = np.meshgrid(pivoted.columns, pivoted.index)\n",
    "\n",
    "    fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "    ax.plot_surface(x, y, pivoted.values, cmap=\"RdPu\", vmin=0)\n",
    "\n",
    "    ax.set_xlabel(columns)\n",
    "    ax.set_ylabel(rows)\n",
    "    ax.set_zlabel(\"error\")\n",
    "    ax.set_title(\"Error Landscape\")\n",
    "\n",
    "plot_error_surface(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a picture is called a **error landscape** (or sometimes loss landscape). It shows which combinations of $a$ and $b$ are good, and which are not so good. We can get the best values for $a$ and $b$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results_df.sort_values(\"error\").iloc[0]\n",
    "best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best possible error that we could achieve is being off by 0.024 seconds, with a parameter of $a = 0.44$ and $b = 0.52$. This gives us a final model of the form:\n",
    "\n",
    "$time = 0.44 * height^{0.52}$\n",
    "\n",
    "If we plot the resulting model, we obtain the following picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = best_result[\"a\"]\n",
    "b = best_result[\"b\"]\n",
    "predictions = predict(falling_times, a, b)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plot_scatter(falling_times)\n",
    "plot_model(falling_times, predictions)\n",
    "plt.title(r\"Model: $time = {\" + str(a) + r\"} * height^{\" + str(b) + r\"}$\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that throught he machine learning approach, we have found a good model to predict the falling time of an object. \n",
    "\n",
    "## A Wrong Model Family\n",
    "It is very important that we choose an appropriate model family - one, that can represent the true structure of our data. Another possibility would have been to model the data as:\n",
    "\n",
    "$time = a * height + b$\n",
    "\n",
    "Using this new model, try to find good values for $a$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(falling_times, a, b):\n",
    "    return a * falling_times[\"height\"] + b\n",
    "\n",
    "def model_quality_plot2(falling_times, a, b):\n",
    "    predictions = predict2(falling_times, a, b)\n",
    "    plot_scatter(falling_times)\n",
    "    plot_model(falling_times, predictions)\n",
    "    plot_error_bars(falling_times, predictions)\n",
    "    \n",
    "    error = mean_absolute_error(falling_times[\"duration\"], predictions)\n",
    "    plt.title(f\"Mean Absolute Error: {error:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS\n",
    "a = .2\n",
    "b = 0.1\n",
    "\n",
    "plt.figure()\n",
    "model_quality_plot2(falling_times, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the best values for $a$ and $b$ using our optimization algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_to_test = np.linspace(start=0, stop=1, num=51)\n",
    "b_to_test = np.linspace(start=0, stop=1, num=51)\n",
    "\n",
    "# results will be filled as a list of dictionaries\n",
    "results2 = []\n",
    "for a in a_to_test:\n",
    "    for b in b_to_test:\n",
    "        predictions = predict2(falling_times, a, b)\n",
    "        error = mean_absolute_error(falling_times[\"duration\"], predictions)\n",
    "        results2.append(\n",
    "            {\n",
    "                \"a\": a,\n",
    "                \"b\": b,\n",
    "                \"error\": error,\n",
    "            }\n",
    "        )\n",
    "\n",
    "results_df2 = pd.DataFrame(results2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model that we could achieve was the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result2 = results_df2.sort_values(\"error\").iloc[0]\n",
    "best_result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error of the new best result is twice as high as with the previous model. The resulting fit looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = best_result2[\"a\"]\n",
    "b = best_result2[\"b\"]\n",
    "predictions = predict2(falling_times, a, b)\n",
    "\n",
    "plt.figure()\n",
    "plot_scatter(falling_times)\n",
    "plot_model(falling_times, predictions)\n",
    "plt.title(f\"Model: $time = {a} * height + {b}$\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the quality of our fit very strongly depends on the model family that we choose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "This example has shown all key ingredients that are needed for a machine learning model.\n",
    "\n",
    "- We need a dataset, on which we can train our model.\n",
    "- We need to define a model family that will be used to fit our model. The model family has parameters, for which we want to find the best values.\n",
    "- We need to define a performance metric and an objective: What to we want to optimize exactly?\n",
    "- We need a optimization algorithm that finds the best parameter values for us.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Write down a definition for the following terms:\n",
    "- **model family**:\n",
    "- **parameter**:\n",
    "- **performance metric**:\n",
    "- **mean absolute error**:\n",
    "- **objective**:\n",
    "- **training**:\n",
    "- **optimization algorithm**:\n",
    "- **error landscape**:\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "According to Newton's second law, the distance travelled by an object without air resistance is given by:\n",
    "\n",
    "$height = \\frac{1}{2} g * time^2, \\quad$ where $g = 9.81m/s^2$.\n",
    "\n",
    "Solve this equation for $time$, and reformulate it to find the true values for $a$ and $b$, in the model family $time = a * height^b$. How close did we get to the true values with machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "This is how the data is generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "noise_amount = .025\n",
    "size = 25\n",
    "\n",
    "height = np.linspace(.2, .2 * size, size)\n",
    "true_duration = (2 * height / 9.81) ** (1/2)\n",
    "\n",
    "# set the random seed such that this is reproducible\n",
    "np.random.seed(123)\n",
    "noise = np.random.normal(0, noise_amount, size=size)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"height\": height,\n",
    "        \"duration\": true_duration + noise,\n",
    "    }\n",
    ")\n",
    "\n",
    "# add 0s for 0m\n",
    "df.loc[-1] = [0, 0]\n",
    "\n",
    "df.sort_index().to_csv(\"data/ball_falling_time.csv\", index=False, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
