{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Feature Datasets\n",
    "\n",
    "In machine learning, the value that we try to predict is called the **target**. The values used to predict the targets are called **features**. \n",
    "\n",
    "For instance: In the previous example, we predicted the falling time depending on the height of the data. Therefore, the time was the target, and the height was the feature. \n",
    "\n",
    "The true power of machine learning is unlocked when we have not a single but many different features. Let's look at such an example in more detail.\n",
    "\n",
    "## Dataset: WHO Life Expectancy\n",
    "\n",
    "The life expectancy dataset lists the life expectancy in different countries, together with further information about these countries. The data is from [WHO](https://www.who.int/data/gho/data/indicators) and [the world bank](https://data.worldbank.org/indicator/NY.GDP.PCAP.CD). It was retrieved on September 2nd, 2024. For all measures, the most recent available value is considered (typically from 2022 or 2023).\n",
    "\n",
    "We want to use this data to predict the life expectancy of a country using different economic and public health indicators, to see if there is any relationship.\n",
    "\n",
    "### Data Loading\n",
    "We can load the data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "life_expectancy = pd.read_csv(\"../data/who_data.csv\", index_col=0)\n",
    "life_expectancy.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the following columns in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_expectancy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal will be to predict the life expectancy in a country using some of the other information on the country. Life expectancy is therefore the target, and the features that we will consider are:\n",
    "\n",
    "*Economic and General Information:*\n",
    "\n",
    "- `GDP`: Gross domestic product in current US$\n",
    "- `CHE`: Current health expenditure (CHE) per capita in US$\n",
    "\n",
    "*Health Indicators:*\n",
    "\n",
    "- `fine_particular_matter`: Concentrations of fine particulate matter (PM2.5)\n",
    "- `prevalence_obesity`: Prevalence of obesity among adults, BMI &GreaterEqual; 30 (crude estimate) (%)\n",
    "- `prevalence_underweight`: Prevalence of underweight among adults, BMI < 18 (crude estimate) (%)\n",
    "- `alcohol_consumption`: Alcohol, total per capita (15+) consumption (in litres of pure alcohol) (SDG Indicator 3.5.2), three-year average\n",
    "\n",
    "*Vaccination Indicators:*\n",
    "\n",
    "- `pol3`: Polio (Pol3) immunization coverage among 1-year-olds (%)\n",
    "- `dpt3`: Diphtheria tetanus toxoid and pertussis (DTP3) immunization coverage among 1-year-olds (%)\n",
    "- `hepB`: Hepatitis B (HepB3) immunization coverage among 1-year-olds (%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Since this is data from the real world, we have to do some **preprocessing** - i.e. cleaning up, before we can do machine learning. We check for missing values in our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_expectancy.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Methods usually cannot deal with missing values - we therefore have to either fill them with plausible values or eliminate entries with missing values. In our case, we just throw away the countries that don't have complete information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_missing_values = life_expectancy.isna().sum(axis=1) == 0\n",
    "life_expectancy = life_expectancy[has_missing_values]\n",
    "\n",
    "life_expectancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 172 countries, which is enough for our analysis.\n",
    "\n",
    "Now, we can split our data into the target and the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = life_expectancy[\"life_expectancy\"]\n",
    "\n",
    "# everything but life expectancy and country name will be a feature\n",
    "features = life_expectancy.drop([\"life_expectancy\", \"Country Name\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Feature Models\n",
    "\n",
    "### Model Family: Linear Regression\n",
    "\n",
    "For this example, we will consider a family of models called linear regression. You can imagine a linear model just fitting a straight line through the data in our scatter plot - anything other than straight lines can't be fitted. They are very easy to work with and always a good place to start, if we don't know what model family is appropriate.\n",
    "\n",
    "A linear model has the form:\n",
    "\n",
    "$target = a_1 * feature_1 + a_2 * feature_2 + a_3 * feature_3 + ... + b$.\n",
    "\n",
    "The parameters to be learned are $a_1, a_2, ...$ and $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first model: Life Expectancy based on GDP\n",
    "\n",
    "We can now start with a first model: Predicting the life expectancy with a single feature, the GDP. If we plot life expectancy against the GDP, we obtain the following picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(features, target, feature_to_plot):\n",
    "    plt.scatter(features[feature_to_plot], target)\n",
    "    plt.xlabel(feature_to_plot)\n",
    "    plt.ylabel(target.name)\n",
    "\n",
    "plot_scatter(features, target, \"GDP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a positive trend: The higher the GDP, the higher the life expectancy. However, the data is poorly distributed: There are two economies with a very high GDP (China and the USA), while the remaining economies have a much lower GDP. \n",
    "\n",
    "We can fit a linear model using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression = LinearRegression()\n",
    "regression.fit(features[[\"GDP\"]], target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fits a model of the type\n",
    "\n",
    "$expectancy = a_1 * GDP + b$.\n",
    "\n",
    "The optimization algorithm to find the best parameter values is conveniently already implemented, and we can obtain the fitted parameter values as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"a1:\", regression.coef_[0])\n",
    "print(\"b:\", regression.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot the values, we see the following picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(regression, index, xlow, xhigh):\n",
    "    a = regression.coef_[index]\n",
    "    b = regression.intercept_\n",
    "\n",
    "    x = np.linspace(xlow, xhigh)\n",
    "    y = a * x + b\n",
    "    plt.plot(x, y, c=\"red\")\n",
    "\n",
    "plot_scatter(features, target, \"GDP\")\n",
    "plot_model(regression, 0, 0, 2.5e13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the fit is rather poor. We can calculate the error as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def calculate_metric(regression, features, target):\n",
    "    # Calculate the prediction\n",
    "    predictions = regression.predict(features)\n",
    "    return mean_absolute_error(target, predictions)\n",
    "\n",
    "print(\"Mean Absolute Error:\", calculate_metric(regression, features[[\"GDP\"]], target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is off by 5.62 years on average, which quite bad. Let's see if we can improve this.\n",
    "\n",
    "### Feature Engineering: GDP\n",
    "\n",
    "We can visually see on the scatter plot that a straight line is a poor fit. In order to improve, we can transform the GDP such that a straight line is a better fit. A good transformation to try is a logarithmic transformation - this will bring the extreme values closer together.\n",
    "\n",
    "As a reminder: The logarithm with base 10 basically calculates how many zeros a number has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the logarithm of the GDP\n",
    "features[\"log_GDP\"] = np.log10(features[\"GDP\"])\n",
    "\n",
    "# Now if we create a scatter plot:\n",
    "plot_scatter(features, target, \"log_GDP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually, it seems like a straight line may be a better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def plot_single_feature_fit(features, target, column):\n",
    "    # Create a Fit\n",
    "    regression = LinearRegression()\n",
    "    regression.fit(features[[column]], target)\n",
    "\n",
    "    plot_scatter(features, target, column)\n",
    "    plot_model(regression, 0, features[column].min(), features[column].max())\n",
    "\n",
    "    plt.title(f\"Mean Absolute Error: {calculate_metric(regression, features[[column]], target):.3f}\")\n",
    "\n",
    "plot_single_feature_fit(features, target, \"log_GDP\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that thanks to this transformation, we have improved our model by 0.6 years. This process of transforming a feature to improve the overall performance is called **feature engineering**.\n",
    "\n",
    "### Feature Engineering: GDP per Capita\n",
    "Another way to perform feature engineering on GDP is to calculate the GDP per capita. By dividing the total economic power by the amount of people in the country, we will obtain a better indicator of how much money there is available per person.\n",
    "\n",
    "We calculate the GDP per capita as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"GDP_per_capita\"] = features[\"GDP\"] / features[\"population\"]\n",
    "\n",
    "plot_single_feature_fit(features, target, \"GDP_per_capita\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit has again greatly improved by creating this new feature, GDP per capita. We can improve the fit even further by calculating the logarithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"log_GDP_per_capita\"] = np.log10(features[\"GDP_per_capita\"])\n",
    "plot_single_feature_fit(features, target, \"log_GDP_per_capita\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this transformation, a straight line looks like a good fit. We have now greatly improved the model: While GDP alone gave us an average error of 5.6, we have now decreased the error to 3.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering: CHE\n",
    "Now let's look at another feature: Current health expenditure (CHE) per capita in US$. If we just use the feature directly, we obtain the following fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_feature_fit(features, target, \"CHE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you engineer a feature from CHE, such that the fit is improved further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "che = features[\"CHE\"]\n",
    "\n",
    "# CHANGE THIS\n",
    "features[\"engineered\"] = np.log10(che)  # do some transformation here\n",
    "\n",
    "# Useful functions:\n",
    "# - che ** a       for some value of a, che^a for every entry in che\n",
    "# - 1 / che        calculate the inverse\n",
    "# - np.sqrt(che)   calculate the square root\n",
    "# - np.exp(che)    to calculate e^che for every value in che\n",
    "# - np.log10(che)  to calculate the logarithm \n",
    "# \n",
    "# a list of all mathematical functions of numpy can be found here: \n",
    "# https://numpy.org/doc/stable/reference/routines.math.html\n",
    "#\n",
    "# If you want to multiply with or divide by another feature, you can do this as follows:\n",
    "# features[\"engineered\"] = che * features[\"other_feature\"]\n",
    "# features[\"engineered\"] = che / features[\"other_feature\"]\n",
    "#\n",
    "# And you can find a list of all features by running:\n",
    "# print(features.columns)\n",
    "\n",
    "plot_single_feature_fit(features, target, \"engineered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Economic Indicators\n",
    "Now let's see if we can improve the fit further by taking into account multiple features.\n",
    "\n",
    "### GDP per capita and our Engineered Feature\n",
    "We start off by looking at the performance if we use log(GDP per capita) and our engineered feature. We can visualize the data on a three-dimensional scatter plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(features, feature_x, feature_y, target, ax):\n",
    "    ax.scatter(features[feature_x], features[feature_y], target, c=target, cmap=\"RdPu\")\n",
    "    ax.set_xlabel(feature_x)\n",
    "    ax.set_ylabel(feature_y)\n",
    "    ax.set_zlabel(\"life expectancy\")\n",
    "\n",
    "%matplotlib ipympl\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "plot_scatter(features, \"log_GDP_per_capita\", \"engineered\", target, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fit the model using two features and calculate our error as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()\n",
    "\n",
    "# define the columns to use in the regression\n",
    "columns = [\"log_GDP_per_capita\", \"engineered\"]\n",
    "\n",
    "regression.fit(features[columns], target)\n",
    "\n",
    "print(\"Mean Absolute Error:\", calculate_metric(regression, features[columns], target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the two features toghether indeed improved our model. \n",
    "\n",
    "### Looking at the Model\n",
    "\n",
    "Our model is now a function that takes two inputs, `log_GDP_per_capita` and `engineered`, and outputs a single prediction. We can visualize it using a three-dimensional plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linspace_from_feature(feature):\n",
    "    return np.linspace(feature.min(), feature.max())\n",
    "\n",
    "def plot_surface(features, feature_x, feature_y, regression, ax):\n",
    "    linspace_x = linspace_from_feature(features[feature_x])\n",
    "    linspace_y = linspace_from_feature(features[feature_y])\n",
    "\n",
    "    x, y = np.meshgrid(linspace_x, linspace_y)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {feature_x: x.flatten(), feature_y: y.flatten()}\n",
    "    )\n",
    "    df[\"prediction\"] = regression.predict(df)\n",
    "\n",
    "    pivoted = df.pivot(index=feature_y, columns=feature_x, values=\"prediction\")\n",
    "\n",
    "    ax.plot_surface(x, y, pivoted.values, alpha=.3, color=\"k\")\n",
    "\n",
    "    ax.set_xlabel(feature_x)\n",
    "    ax.set_ylabel(feature_y)\n",
    "    ax.set_zlabel(\"life expectancy\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "plot_surface(features, \"log_GDP_per_capita\", \"engineered\", regression, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear regression with two input variables will fit a surface through the points. We can visualize both the true data points and the model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "plot_surface(features, \"log_GDP_per_capita\", \"engineered\", regression, ax)\n",
    "plot_scatter(features, \"log_GDP_per_capita\", \"engineered\", target, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even More Features\n",
    "\n",
    "We can add even more features to our model. We can no longer visualize these models - such visualizations would require more than three dimensions. But the process of fitting and evaluating remains the same.\n",
    "\n",
    "Let's add the fine particular matter information. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()\n",
    "\n",
    "# define the columns to use in the regression\n",
    "columns = [\"log_GDP_per_capita\", \"engineered\", \"fine_particular_matter\"]\n",
    "\n",
    "regression.fit(features[columns], target)\n",
    "\n",
    "print(\"Mean Absolute Error:\", calculate_metric(regression, features[columns], target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did not improve the fit - somewhat surprisingly. This has two interpretations:\n",
    "- Air quality does not affect the life expectancy, or\n",
    "- air quality is already captured by the other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Find the best model\n",
    "\n",
    "Try out different feature combinations. With what combination of features can we obtain the best model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all possible columns:\n",
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS\n",
    "# put all features you want to use in this list\n",
    "columns = ['population', 'GDP', 'pol3', 'dpt3', 'prevalence_obesity',\n",
    "       'fine_particular_matter', 'hepB', 'CHE', 'prevalence_underweight',\n",
    "       'alcohol_consumption', 'log_GDP', 'GDP_per_capita',\n",
    "       'log_GDP_per_capita', 'engineered']\n",
    "\n",
    "# DON'T CHANGE THIS\n",
    "regression = LinearRegression()\n",
    "regression.fit(features[columns], target)\n",
    "\n",
    "print(\"Mean Absolute Error:\", calculate_metric(regression, features[columns], target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus**: Can you improve your model even further, by doing more feature engineering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can create a new features like this:\n",
    "features[\"new_feature_1\"] = 1  # put some expression here instead of 1\n",
    "features[\"new_feature_2\"] = 2\n",
    "\n",
    "# then add the new feature name to the list\n",
    "columns = [\"log_GDP_per_capita\", \"engineered\", \"fine_particular_matter\", \"new_feature_1\", \"new_feature_2\"]\n",
    "\n",
    "# and run the following\n",
    "# DON'T CHANGE THIS\n",
    "regression = LinearRegression()\n",
    "regression.fit(features[columns], target)\n",
    "\n",
    "print(\"Mean Absolute Error:\", calculate_metric(regression, features[columns], target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Write down a definition for the following terms:\n",
    "\n",
    "- **target**:\n",
    "- **feature**:\n",
    "- **feature engineering**:\n",
    "- **linear regression**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Data Combination\n",
    "\n",
    "Here's the code for combining the original data into a single dataframe. No need to understand this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_who_data(path, file, description_file):\n",
    "    df = pd.read_csv(path + file)\n",
    "    pivoted = df.pivot(index=\"SpatialDimValueCode\", columns=\"Indicator\", values=\"FactValueNumeric\")\n",
    "\n",
    "    # name column after file (the original column names are impossibly long)\n",
    "    new_column_name, _ = os.path.splitext(file)\n",
    "    measure_name = pivoted.columns[0]\n",
    "\n",
    "    # append the renaming to the description file\n",
    "    with open(description_file, mode=\"a\") as file:\n",
    "        file.write(f\"{new_column_name}: {measure_name}\\n\")\n",
    "\n",
    "    return pivoted.rename({measure_name: new_column_name}, axis=1)\n",
    "\n",
    "def read_world_bank_data(path, file, description_file):\n",
    "    df = pd.read_csv(path + file, sep=\",\", skiprows=3)\n",
    "    indicator_name = df[\"Indicator Name\"].iloc[0]\n",
    "\n",
    "    # name column after file (the original column names are impossibly long)\n",
    "    new_column_name, _ = os.path.splitext(file)\n",
    "\n",
    "    # append the renaming to the description file\n",
    "    with open(description_file, mode=\"a\") as file:\n",
    "        file.write(f\"{new_column_name}: {indicator_name}\\n\")\n",
    "\n",
    "    return df.set_index([\"Country Name\", \"Country Code\"])[[\"2022\"]].rename({\"2022\": new_column_name}, axis=1)\n",
    "\n",
    "def read_gdp():\n",
    "    df = pd.read_csv(\"data/world_bank_data/gdp.csv\", sep=\",\")\n",
    "    return df.set_index(\"Country Code\")[[\"Country Name\", \"2022\"]].rename({\"2022\": \"GDP_per_capita\"}, axis=1)\n",
    "\n",
    "\n",
    "def create_dataset():\n",
    "    # description file is generated automatically\n",
    "    description_file = \"data/who_data/description.txt\"\n",
    "    if os.path.exists(description_file):\n",
    "        os.remove(description_file)\n",
    "\n",
    "    who_data = pd.concat(\n",
    "        [\n",
    "            read_who_data(\"data/who_data/\", file, description_file)\n",
    "            for file in os.listdir(\"data/who_data\")\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    world_bank_data = pd.concat(\n",
    "        [\n",
    "            read_world_bank_data(\"data/world_bank_data/\", file, description_file)\n",
    "            for file in os.listdir(\"data/world_bank_data\")\n",
    "            if file.endswith(\".csv\")\n",
    "        ],\n",
    "        axis=1\n",
    "    ).reset_index(level=0)\n",
    "    full_data = world_bank_data.join(who_data, how=\"inner\")\n",
    "    return full_data\n",
    "\n",
    "\n",
    "who_data = create_dataset()\n",
    "who_data.to_csv(\"data/who_data.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
